{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvMapNetDataset(Dataset):\n",
    "    def __init__(self, images_path, type):\n",
    "        self.__images_path = os.path.join(images_path, type)\n",
    "        self.__images = os.listdir(self.__images_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.__images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = os.path.join(self.__images_path, self.__images[index])\n",
    "        data = np.load(image_path)\n",
    "        data = torch.from_numpy(np.array([data[:,:,0], data[:,:,1], data[:,:,2]]))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1Loss(orig, pred, mask):\n",
    "    return (orig * mask - pred * mask).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2Loss(orig, pred):\n",
    "    return (orig - pred).norm().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FakeRealLoss(orig, pred):\n",
    "    return (orig.log() + (1 - pred).log()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdversarialLoss(pred):\n",
    "    return -pred.log().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ORBPatcher:\n",
    "    def __init__(self, *, key_points=1000):\n",
    "        self.__orb = cv2.ORB_create(key_points)\n",
    "\n",
    "    def __call__(self, image):\n",
    "        key_points, _ = self.__orb.detectAndCompute(image, None)\n",
    "\n",
    "        res = np.zeros((image.shape[0], image.shape[1]), dtype=np.int)\n",
    "        for point in key_points:\n",
    "            x, y = map(np.int, point.pt)\n",
    "            res[y, x] = 1\n",
    "\n",
    "        res == 1\n",
    "        return res.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansFiles:\n",
    "    def __init__(self, orb, *, clusters=5, n_iter=300, partitions=1):\n",
    "        self.__orb = orb\n",
    "        self.__clusters = clusters\n",
    "        self.__n_iter = n_iter\n",
    "        self.__partitions = partitions\n",
    "\n",
    "        self.__centers = None\n",
    "\n",
    "        self.__centers_save_path = os.path.join('k_means.bin')\n",
    "\n",
    "    def fit(self, files):\n",
    "        partition = (len(files) + self.__partitions - 1) // self.__partitions\n",
    "        print('preparing partitions\\n')\n",
    "        for num in range(self.__partitions):\n",
    "            tmp = self.__prepare_partition(files[num::self.__partitions])\n",
    "            torch.save(tmp, os.path.join('{}.pt'.format(num)))\n",
    "            print('partition {} prepared'.format(num))\n",
    "        print('partitions prepared\\n'.format(len(files)))\n",
    "\n",
    "        print('fitting k-means on {} samples\\n'.format(len(files)))\n",
    "        for iteration in range(self.__n_iter):\n",
    "            for num in range(self.__partitions):\n",
    "                tmp = torch.load(os.path.join('{}.pt'.format(num)))\n",
    "                print('fitting on partition {}'.format(num))\n",
    "                self.__fit_partition(tmp)\n",
    "                print('partition fitted!\\n')\n",
    "            print('iteration {} fitted!\\n'.format(iteration))\n",
    "            if (iteration + 1) % 10:\n",
    "                self.save()\n",
    "        print('k-means ready!')\n",
    "\n",
    "        self.__centers = self.__centers.to(device)\n",
    "\n",
    "    def __prepare_partition(self, files):\n",
    "        return torch.tensor([\n",
    "            self.__orb((((np.load(file)) + 1) / 2 * 255).astype(np.uint8))\n",
    "            for file in files\n",
    "        ])\n",
    "\n",
    "    def __fit_partition(self, orig):\n",
    "        x = orig * 1.0\n",
    "\n",
    "        n, d = x.shape\n",
    "        if self.__centers is None:\n",
    "            self.__centers = x[:self.__clusters, :].clone() * 1.0\n",
    "\n",
    "        x_i = x.view(n, 1, d)\n",
    "        c_j = self.__centers.view(1, self.__clusters, d)\n",
    "\n",
    "        D_ij = ((x_i - c_j) ** 2).sum(-1)\n",
    "        clusters = D_ij.argmin(dim=1).long().view(-1)\n",
    "\n",
    "        self.__centers.zero_()\n",
    "        self.__centers.scatter_add_(0, clusters[:, None].repeat(1, d), x)\n",
    "\n",
    "        Ncl = torch.bincount(clusters, minlength=self.__clusters)\n",
    "        Ncl = Ncl.type_as(self.__centers)\n",
    "        Ncl = Ncl.view(self.__clusters, 1)\n",
    "        self.__centers /= Ncl\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.__centers == None:\n",
    "            print('k-means wasn\\'t fitted')\n",
    "            return\n",
    "\n",
    "        n, d = x.shape\n",
    "        x_i = x.view(n, 1, d)\n",
    "        c_j = self.__centers.view(1, self.__clusters, d)\n",
    "        D_ij = ((x_i - c_j) ** 2).sum(-1)\n",
    "        clusters = D_ij.argmin(dim=1).long().view(-1)\n",
    "\n",
    "        res = torch.zeros((n, self.__clusters), requires_grad=False).to(device)\n",
    "        for num, item in enumerate(clusters):\n",
    "            res[num, item] = 1\n",
    "        return res\n",
    "\n",
    "    def save(self):\n",
    "        torch.save(self.__centers, self.__centers_save_path)\n",
    "\n",
    "    def load(self):\n",
    "        self.__centers = torch.load(self.__centers_save_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterLoss:\n",
    "    def __init__(self, orb, *, train_k_means=False, partitions=5, clusters=5):\n",
    "        self.__orb = orb\n",
    "\n",
    "        self.__k_means = KMeansFiles(orb, clusters=clusters, partitions=partitions)\n",
    "        if train_k_means:\n",
    "            self.__k_means.fit(self.__prepare_data())\n",
    "            self.__k_means.save()\n",
    "        else:\n",
    "            self.__k_means.load()\n",
    "\n",
    "    def __call__(self, images, pred):\n",
    "        if device != 'cpu':\n",
    "            images = images.detach().cpu().numpy()\n",
    "        else:\n",
    "            images = images.detach().numpy()\n",
    "\n",
    "        images = np.array([\n",
    "            np.concatenate([\n",
    "                image[0].reshape(*image[0].shape, 1),\n",
    "                image[1].reshape(*image[1].shape, 1),\n",
    "                image[2].reshape(*image[2].shape, 1),\n",
    "            ], axis=2) for image in images\n",
    "        ])\n",
    "        \n",
    "        base = self.__k_means.predict(torch.tensor([\n",
    "            self.__orb(((image + 1) * 255 / 2).astype(np.uint8))\n",
    "            for image in images\n",
    "        ]).to(device))\n",
    "\n",
    "        return -(base * torch.log(pred + 1e-9)).sum()\n",
    "\n",
    "    def __prepare_data(self):\n",
    "        catalogs = [\n",
    "            os.path.join('LavalIndoorHDRDatasetReady', 'train'),\n",
    "            os.path.join('PanoIndoorLDRDatasetReady', 'test'),\n",
    "            os.path.join('LavalIndoorHDRDatasetReady', 'train'),\n",
    "            os.path.join('PanoIndoorLDRDatasetReady', 'test')\n",
    "        ]\n",
    "        files = []\n",
    "        for catalog in catalogs:\n",
    "            files.extend([os.path.join(catalog, file) for file in os.listdir(catalog)])\n",
    "        return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionLoss:\n",
    "    def __init__(self, *, generate_masks=False, masks_count=50, base_shape=(1024, 2048)):\n",
    "        self.__masks_path = 'masks'\n",
    "\n",
    "        if generate_masks:\n",
    "            self.__masks = [\n",
    "                self.__build_mask(base_shape)\n",
    "                for _ in range(masks_count)\n",
    "            ]\n",
    "            for num, mask in enumerate(self.__masks):\n",
    "                path = os.path.join(self.__masks_path, str(num + 1))\n",
    "                np.save(path, mask)\n",
    "        else:\n",
    "            self.__masks = []\n",
    "            for i in range(masks_count):\n",
    "                path = os.path.join(self.__masks_path, str(num + 1))\n",
    "                self.__masks.append(np.load(path))\n",
    "\n",
    "    def __call__(self, orig, pred):\n",
    "        res = torch.zeros(1)\n",
    "\n",
    "        for mask_np in self.__masks:\n",
    "            mask = torch.from_numpy(mask_np).set_grad_enabled(False)\n",
    "            res += torch.abs((orig * mask).sum() - (pred * mask).sum())\n",
    "\n",
    "        return res\n",
    "\n",
    "    def __build_mask(self, base_shape):\n",
    "        base_shape = (*base_shape, 3)\n",
    "        image = np.zeros(base_shape)\n",
    "\n",
    "        for _ in range(int(random.gauss(4, 0.7))):\n",
    "            scale = random.randint(10, 40)\n",
    "\n",
    "            h, w, _ = base_shape\n",
    "            h = h * scale // 100\n",
    "            w = w * scale // 100\n",
    "\n",
    "            tmp = np.ones((h, w, 3)) * 255\n",
    "\n",
    "            angle = random.randint(0, 180)\n",
    "\n",
    "            M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1)\n",
    "            tmp = cv2.warpAffine(tmp, M, (w, h))\n",
    "\n",
    "            h_c = random.randint(base_shape[0] // 3, 2 * base_shape[0] // 3)\n",
    "            w_c = random.randint(base_shape[1] // 3, 2 * base_shape[1] // 3)\n",
    "\n",
    "            top_pad = base_shape[0] - h_c - h // 2\n",
    "            bottom_pad = h_c - h // 2 - h % 2\n",
    "\n",
    "            right_pad = base_shape[1] - w_c - w // 2\n",
    "            left_pad = w_c - w // 2 - w % 2\n",
    "\n",
    "            tmp = np.pad(tmp, ((top_pad, bottom_pad), (left_pad, right_pad), (0, 0)))\n",
    "\n",
    "            image = cv2.add(image, tmp)\n",
    "\n",
    "        return (image == 0).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvMapNetLoss:\n",
    "    def __init__(self):\n",
    "        self.ClusterLoss = ClusterLoss()\n",
    "        self.ProjectionLoss = ProjectionLoss()\n",
    "\n",
    "    def __call__(self, orig, mask, pred, discriminator):\n",
    "        return\\\n",
    "            0.5 * L1Loss(orig, pred, mask) +\\\n",
    "            0.01 * L2Loss(orig, pred) +\\\n",
    "            self.ProjectionLoss(orig, pred) +\\\n",
    "            AdversarialLoss(discriminator(pred)) +\\\n",
    "            self.ClusterLoss(orig, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorLoss:\n",
    "    def __init__(self):\n",
    "        self.ClusterLoss = ClusterLoss()\n",
    "\n",
    "    def __call__(self, orig, pred):\n",
    "        return\\\n",
    "            FakeRealLoss(orig, pred) +\\\n",
    "            self.ClusterLoss(orig, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvMapNetConvBlock(nn.Module):\n",
    "    def __init__(self, channels, *, sets_count=5, conv_channels=16):\n",
    "        super(EnvMapNetConvBlock, self).__init__()\n",
    "        self.__blocks = nn.Sequential(*[\n",
    "            item for sublist in [\n",
    "                self.__get_set(channels, conv_channels, i)\n",
    "                for i in range(sets_count)\n",
    "            ] for item in sublist\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        short_cut = x\n",
    "        counter = 0\n",
    "        for block in self.__blocks:\n",
    "            x = block(x)\n",
    "            counter += 1\n",
    "            if counter == 3:\n",
    "                x = torch.cat((x, short_cut), 1)\n",
    "                short_cut = x\n",
    "                counter = 0\n",
    "        return x\n",
    "    \n",
    "    def __get_set(self, in_channels, conv_channels, i):\n",
    "        channels = in_channels + conv_channels * i\n",
    "        return [\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Conv2d(\n",
    "                channels,\n",
    "                conv_channels,\n",
    "                kernel_size=(3, 3),\n",
    "                padding=(1, 1),\n",
    "                padding_mode='random',\n",
    "            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvMapNetDownsampleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EnvMapNetDownsampleBlock, self).__init__()\n",
    "        self.__conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            padding=(1, 1),\n",
    "            padding_mode='random',\n",
    "        )\n",
    "        self.__downsample = nn.AvgPool2d((2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.__conv(x)\n",
    "        x = self.__downsample(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvMapNetUpsampleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EnvMapNetUpsampleBlock, self).__init__()\n",
    "        self.__conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            padding=(1, 1),\n",
    "            padding_mode='random',\n",
    "        )\n",
    "        self.__upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.__upsample(x)\n",
    "        x = self.__conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dk_orig, uk_orig, *, sets_count=5,\n",
    "                 conv_channels=16, neck_channels=64):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        dk = [3] + dk_orig\n",
    "        self.__downsampling_blocks = nn.Sequential(*[\n",
    "            item for sublist in [\n",
    "                [\n",
    "                    EnvMapNetConvBlock(\n",
    "                        dk[i - 1],\n",
    "                        sets_count=sets_count,\n",
    "                        conv_channels=conv_channels\n",
    "                    ),\n",
    "                    EnvMapNetDownsampleBlock(\n",
    "                        dk[i - 1] + sets_count * conv_channels,\n",
    "                        dk[i]\n",
    "                    )\n",
    "                ]\n",
    "                for i in range(1, len(dk))\n",
    "            ] for item in sublist\n",
    "        ])\n",
    "\n",
    "        self.__neck = nn.Conv2d(\n",
    "            dk[-1],\n",
    "            neck_channels,\n",
    "            kernel_size=(1, 1),\n",
    "        )\n",
    "\n",
    "        uk = [neck_channels] + uk_orig\n",
    "        self.__upsampling_blocks = nn.Sequential(*[\n",
    "            item for sublist in [\n",
    "                [\n",
    "                    EnvMapNetUpsampleBlock(\n",
    "                        uk[i - 1] + (i != 1) *\n",
    "                            (sets_count * conv_channels),\n",
    "                        uk[i]),\n",
    "                    EnvMapNetConvBlock(\n",
    "                        uk[i],\n",
    "                        sets_count=sets_count,\n",
    "                        conv_channels=conv_channels\n",
    "                    )\n",
    "                ]\n",
    "                for i in range(1, len(uk))\n",
    "            ] for item in sublist\n",
    "        ])\n",
    "\n",
    "        self.__out = nn.Conv2d(\n",
    "            uk[-1] + sets_count * conv_channels,\n",
    "            3,\n",
    "            kernel_size=(3, 3),\n",
    "            padding=(1, 1),\n",
    "            padding_mode='random',\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.__downsampling_blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.__neck(x)\n",
    "\n",
    "        for block in self.__upsampling_blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.__out(x)\n",
    "\n",
    "        return torch.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, *, sets_count=2):\n",
    "        super(DiscriminatorResidualBlock, self).__init__()\n",
    "        self.__avg = nn.AvgPool2d((2, 2))\n",
    "        self.__conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            padding=(1, 1),\n",
    "            padding_mode='random',\n",
    "        )\n",
    "\n",
    "        self.__blocks = nn.Sequential(*[\n",
    "            item for sublist in [\n",
    "                self.__get_set(in_channels if i == 0 else out_channels, out_channels)\n",
    "                for i in range(sets_count)\n",
    "            ] for item in sublist\n",
    "        ])\n",
    "\n",
    "    def forward(self, inp):\n",
    "        sc = self.__avg(inp)\n",
    "        sc = self.__conv(sc)\n",
    "        sc = nn.functional.pad(\n",
    "            sc, (sc.shape[-1] // 2, sc.shape[-1] // 2, sc.shape[-2] // 2, sc.shape[-2] // 2)\n",
    "        )\n",
    "\n",
    "        x = inp\n",
    "        for block in self.__blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        return x + sc\n",
    "    \n",
    "    def __get_set(self, in_channels, out_channels):\n",
    "        return [\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=(3, 3),\n",
    "                padding=(1, 1),\n",
    "                padding_mode='random',\n",
    "            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ak_orig, *, sets_count=2):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        ak = [3] + ak_orig\n",
    "\n",
    "        self.__blocks = nn.Sequential(*[\n",
    "            DiscriminatorResidualBlock(ak[i - 1], ak[i], sets_count=sets_count)\n",
    "            for i in range(1, len(ak))\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.__blocks:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dk = [64, 128, 128, 128, 256, 256, 512]\n",
    "uk = [512, 256, 256, 128, 128, 128, 64]\n",
    "ak = [64, 128, 256, 256, 256, 256, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_size = 16\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = nn.DataParallel(Generator(dk, uk)).to(device)\n",
    "discriminator = nn.DataParallel(Discriminator(ak)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train_dataloader = DataLoader(\n",
    "    EnvMapNetDataset(os.path.join('LavalIndoorHDRDatasetReady'), type='train'), batch_size=minibatch_size, shuffle=True\n",
    ")\n",
    "generator_test_dataloader = DataLoader(\n",
    "    EnvMapNetDataset(os.path.join('LavalIndoorHDRDatasetReady'), type='test'), batch_size=minibatch_size, shuffle=True\n",
    ")\n",
    "discriminator_train_dataloader = DataLoader(\n",
    "    EnvMapNetDataset(os.path.join('PanoIndoorLDRDatasetReady'), type='train'), batch_size=minibatch_size // 2, shuffle=True\n",
    ")\n",
    "discriminator_test_dataloader = DataLoader(\n",
    "    EnvMapNetDataset(os.path.join('PanoIndoorLDRDatasetReady'), type='test'), batch_size=minibatch_size // 2, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_loss = EnvMapNetLoss()\n",
    "discriminator_loss = DiscriminatorLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimiser = torch.optim.Adam(generator.parameters(), lr=0.0002)\n",
    "discriminator_optimiser = torch.optim.Adam(discriminator.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_mask = torch.from_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(generator,\n",
    "               generator_train_dataloader,\n",
    "               generator_loss,\n",
    "               generator_optimiser,\n",
    "               discriminator,\n",
    "               discriminator_train_dataloader,\n",
    "               discriminator_loss,\n",
    "               discriminator_optimiser\n",
    "              ):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    g_size = len(generator_train_dataloader.dataset)\n",
    "    d_size = len(discriminator_train_dataloader.dataset)\n",
    "\n",
    "    for batch, (g_data, d_data) in enumerate(zip(\n",
    "        generator_train_dataloader,\n",
    "        discriminator_train_dataloader\n",
    "    )):\n",
    "        mask = build_random_masks()\n",
    "\n",
    "        g_data = g_data.to(device)\n",
    "        g_pred = generator(g_data * mask)\n",
    "        g_loss = generator_loss(g_data, mask, g_pred, discriminator)\n",
    "        generator_optimiser.zero_grad()\n",
    "        g_loss.backward()\n",
    "        generator_optimiser.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = g_loss.item(), batch * len(g_data)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{g_size:>5d}]\")\n",
    "\n",
    "        d_data = d_data.to(device)\n",
    "        d_pred = discriminator(d_data)\n",
    "        d_loss = discriminator_loss(d_data, d_pred)\n",
    "        discriminator_optimiser.zero_grad()\n",
    "        d_loss.backward()\n",
    "        discriminator_optimiser.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = d_loss.item(), batch * len(d_data)\n",
    "            print(f\"loss: {d_loss:>7f}  [{current:>5d}/{d_size:>5d}]\")\n",
    "            print()\n",
    "\n",
    "\n",
    "def test_loop(generator,\n",
    "              generator_test_dataloader,\n",
    "              generator_loss,\n",
    "              discriminator,\n",
    "              discriminator_test_dataloader,\n",
    "              discriminator_loss\n",
    "             ):\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "\n",
    "    g_size = len(generator_test_dataloader.dataset)\n",
    "    d_size = len(discriminator_test_dataloader.dataset)\n",
    "    g_loss, d_loss = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for g_data, d_data in zip(\n",
    "            generator_train_dataloader,\n",
    "            discriminator_train_dataloader\n",
    "        ):\n",
    "            mask = build_random_masks()\n",
    "\n",
    "            g_data = g_data.to(device)\n",
    "            g_pred = generator(g_data * mask)\n",
    "            g_loss += generator_loss(g_data, mask, g_pred, discriminator).item()\n",
    "\n",
    "            d_data = d_data.to(device)\n",
    "            d_pred = discriminator(d_data)\n",
    "            d_loss += discriminator_loss(d_data, d_pred).item()\n",
    "\n",
    "    g_loss /= g_size\n",
    "    d_loss /= d_size\n",
    "\n",
    "    print(\"Test Error:\")\n",
    "    print(f\" Avg generator loss: {g_loss:>8f}\")\n",
    "    print(f\" Avg discriminator loss: {d_loss:>8f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t + 1} started\")\n",
    "    train_loop(\n",
    "        generator,\n",
    "        generator_train_dataloader,\n",
    "        generator_loss,\n",
    "        generator_optimiser,\n",
    "        discriminator,\n",
    "        discriminator_train_dataloader,\n",
    "        discriminator_loss,\n",
    "        discriminator_optimiser\n",
    "    )\n",
    "    print(f\"Epoch {t + 1} trained\")\n",
    "    test_loop(\n",
    "        generator,\n",
    "        generator_test_dataloader,\n",
    "        generator_loss,\n",
    "        discriminator,\n",
    "        discriminator_test_dataloader,\n",
    "        discriminator_loss\n",
    "    )\n",
    "    print(f\"Epoch {t + 1} tested\\n\")\n",
    "    if (t + 1) % 10 == 0:\n",
    "        torch.save(generator.state_dict(), os.path.join('generator'))\n",
    "        torch.save(discriminator.state_dict(), os.path.join('discriminator'))\n",
    "        print(f\"Model by epoch {t + 1} saved\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
